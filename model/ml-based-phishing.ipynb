{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Importing libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom urllib.parse import urlparse\nfrom re import findall\n\nimport keras_tuner as kt\nfrom sklearn.ensemble import RandomForestClassifier\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = pd.read_csv('/kaggle/input/malicious-urls-dataset/malicious_phish.csv')\ndf2 = pd.read_csv('/kaggle/input/urldataset/data.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Analysing 2 different Dataset","metadata":{}},{"cell_type":"code","source":"df1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.type.unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = df1.replace({'type':{'phishing':'bad','defacement':'bad','malware':'bad','benign':'good'}})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.type.unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.rename(columns={'type':'label'},inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Combining 2 different Datasets","metadata":{}},{"cell_type":"code","source":"df = pd.concat([df1,df2],axis=0)\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop_duplicates()\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Feature Extraction","metadata":{}},{"cell_type":"markdown","source":"Checking dtype of url","metadata":{}},{"cell_type":"code","source":"x = df['url'][0]\nx","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We get to know that it is object","metadata":{}},{"cell_type":"code","source":"def getHostname(url):\n    try:\n        parsedUrl = urlparse(url)\n        if (parsedUrl.scheme == ''):\n            return str(urlparse('http://'+url).hostname)\n        return str(parsedUrl.hostname)\n    except:\n        return url","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getPortN(url):\n    try:\n        parsedUrl = urlparse(url)\n        if (parsedUrl.scheme == ''):\n            port = urlparse('http://'+url).port\n        else:\n            port = parsedUrl.port\n        if port is None:\n            return 80\n        else:\n            return port\n    except:\n        return 80","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def hasSuspiciousSymbol(url):\n    checkSymbol = ['=','?','%','+','$','!','*',',','@'] \n    # '=','?','%' => used for GET Request. \n    # More possibility of Phishing site. \n    for symbol in checkSymbol:\n        if symbol in url:\n            return True\n    return False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['numberDots'] = [url.count('.') for url in df['url']]\ndf['numberHyphen'] = [url.count('-') for url in df['url']]\ndf['numberDigits'] = [len(findall(r'/\\d/', url)) for url in df['url']]\ndf['urlLen'] = [len(url) for url in df['url']]\ndf['hostNameLen'] = [len(getHostname(url)) for url in df['url']]\ndf['pathLen'] = [len(str(urlparse(url).path)) for url in df['url']]\ndf['numberBackSlash'] = [url.count('/') for url in df['url']]\ndf['hasHttps'] = [1 if 'https' in url else 0 for url in df['url']]\ndf['portN'] = [getPortN(url) for url in df['url']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.replace({'label':{'bad':0,'good':1}})\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Split Dataset into Train Test","metadata":{}},{"cell_type":"code","source":"df = df.drop(['url'],axis=1)\nX = df.drop(['label'],axis=1)\nY = df['label']\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=1050)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Model Dev","metadata":{}},{"cell_type":"code","source":"modelRF = RandomForestClassifier()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Random Forest and Keras-NN is chosen as 2 of the complex Classifiers. Can run a lot and lot of data present. \nRF = 1000s of Decision Trees and strong Classifier\nKeras - NN = Custom trained on dataset. Majorly Good results expected.","metadata":{}},{"cell_type":"code","source":"hyperparam = {'n_estimators':[50,75,100,125,150]}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = GridSearchCV(\n    estimator = modelRF,\n    param_grid = hyperparam,\n    #cv=5,#5 fold cross validation\n    verbose = 1,\n    n_jobs = -1)#Uses all the CPU Cores for you","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf.fit(X=X_train,y=y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmodelNN = Sequential() \nmodelNN.add(Dense(32, input_shape=(9,), activation='relu'))\nmodelNN.add(Dense(64, activation='relu'))\nmodelNN.add(Dense(128, activation='relu'))\nmodelNN.add(Dense(64, activation='relu'))\nmodelNN.add(Dense(32, activation='relu'))\nmodelNN.add(Dense(1, activation='sigmoid'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelNN.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodelNN.fit(X_train, y_train, epochs=10, batch_size=2048, verbose=1, validation_split=0.1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}